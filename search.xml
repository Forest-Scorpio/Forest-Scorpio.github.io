<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>集成学习总结</title>
      <link href="/2021/07/20/ensemble/"/>
      <url>/2021/07/20/ensemble/</url>
      
        <content type="html"><![CDATA[<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><ul><li><p>集成学习 <code>(ensemble learning)</code> 是通过构建及结合多个学习器来完成学习任务的，其一般结构为：</p><ul><li><p>先产生一组个体学习器 <code>(individual learner)</code>。个体学习器通常由一种或多种现有的学习算法从训练数据中产生</p></li><li><p>然后使用某种 <code>strategy</code> 将个体学习器结合起来。通常可以获得比单一学习器显著优越的泛化性能</p></li></ul></li><li><p>选取基学习器的准则：好而不同</p><ul><li><p>个体学习器要具备一定的准确性，预测能力不能太差</p></li><li><p>个体学习器之间要有差异</p></li></ul></li><li><p>一个简单的理论分析：</p><p>考虑一个二分类问题 $y\in -1, +1$，真实函数 $f(x)$ 及奇数 $M$ 个相互独立的犯错概率为 $\epsilon$ 的个体学习器 $h_i(x)$，我们使用简单的投票 <code>(voting)</code> 规则进行决策：</p><script type="math/tex; mode=display">H(x)=sign(\sum_{i=1}^{M}h_i(x))</script><p>由 $Hoeffding$ 不等式可知，集成学习的犯错概率满足：</p><script type="math/tex; mode=display">P(H(x) \not = f(x))= \sum_{k=1}^{(M+1)/2}C_{M}^{k}(1-\epsilon)^k\epsilon^{M-k} \le exp{(-\frac{1}{2}M(1-2\epsilon)^2)}</script><p>当基学习器的个数 $M$ 很大的时候，集成学习的犯错概率将接近于 $0$。这也很符合人们的直觉：大多数人同时犯错的概率将很低。</p></li><li><p>根据基学习器的生成方式，目前的集成学习方法大概分成两类：</p><ul><li>个体学习器之间存在强依赖关系，必须串行生成的序列化方法，每一轮迭代生成一个个体学习器，其中以 <code>Boosting</code> 为代表</li><li>个体学习器之间不存在强依赖关系， 可以同时生成的并行化方法，其中以 <code>Bagging</code> 和 <code>Random Forest</code> 为代表</li></ul></li></ul><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a><code>Boosting</code></h2><p><code>Boosting</code> 的主要思想是将弱的基学习器提升为强学习器，在分类问题中，它通过改变训练样本的权重学习多个分类器，并将这些分类器们进行线性组合来提高分类的能力。其主要步骤为：</p><ul><li><p>先用样本权重相等的训练集学习一个初始的基学习器</p></li><li><p>根据上一轮得到的学习器在训练集上的表现情况调整样本权重（<strong>提高被上一轮学习器分类错误的样本的权重，使之再下一轮训练中得到更多关注</strong>），然后据此学习一个新的基学习器</p></li><li><p>重复第二步直到得到$M$个学习器，最后的集成学习器为$M$个学习器的组合</p></li></ul><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a><code>Bagging</code></h2><p><code>Bagging</code> 直接基于自主采样 <code>Boostrap Sampling</code>。自主采样的一般步骤为：</p><ul><li><p>先随机取出一个样本放入采样集中，再把该样本放回原始数据集。</p></li><li><p>这样经过$N$次随机采样操作，得到包含$N$个样本的采样集。</p></li></ul><blockquote><p>初始训练集中有的样本在采样集中多次出现，有的则从未出现。初始训练集中约有 $63.2\%$ 的样本出现在了采样集中。因此剩下的约 $36.8\%$ 的样本可用作验证集来对泛化性能进行包外估计。</p></blockquote><p><code>Bagging</code>方法的主要步骤为：</p><ul><li><p>经过 $M$ 轮自助采样，可以得到 $M$ 个包含 $N$ 个训练样本的采样集。</p></li><li><p>然后基于每个采样集训练出一个基学习器。</p></li><li><p>最后将这$M$个基学习器进行组合，得到集成模型。</p></li></ul><h2 id="偏差-方差分解"><a href="#偏差-方差分解" class="headerlink" title="偏差-方差分解"></a>偏差-方差分解</h2><blockquote><script type="math/tex; mode=display">Error = bias + var_f + var_{\epsilon}</script><p>即泛化误差可以分解为偏差、方差和噪声之和：</p><p><strong>偏差</strong>：度量了学习算法的期望预测与真实结果之间的偏离程度，刻画了<strong>学习算法本身的拟合能力</strong>。</p><p><strong>方差</strong>：度量了训练集的变动所导致的学习性能的变化，刻画了<strong>数据扰动造成的影响</strong>。</p><p><strong>噪声</strong>：度量了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了<strong>学习问题本身的难度</strong>。</p><p><strong>偏差-方差分解表明：泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。</strong></p></blockquote><p>在 <code>Bagging</code> 和 <code>Boosting</code> 框架中，通过计算基模型的期望和方差我们可以得到模型整体的期望和方差。为了简化模型，我们假设基模型的期望为 $\mu$ ，方差 $\sigma^2$ ，模型的权重为 $r$，两两模型间的相关系数 $\rho$ 相等。由于 <code>Bagging</code> 和 <code>Boosting</code> 的基模型都是线性组成的，那么有：</p><script type="math/tex; mode=display">F=\sum_{i}^m r_if_i</script><script type="math/tex; mode=display">E(F) = \sum_{i}^m r_iE(f_i)</script><script type="math/tex; mode=display">var(F) = var(\sum_{i}^m r_if_i)</script><blockquote><p>对于 <code>Bagging</code> 来说，每个基模型的权重等于 $1/m$ 且期望近似相等。</p><ul><li><p>整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。</p></li><li><p>整体模型的方差小于等于基模型的方差，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。</p></li><li><p>因此 <code>Bagging</code> 中的基模型一定要为强模型。</p></li></ul><p>对于 <code>Boosting</code> 来说，由于基模型共用同一套训练集，所以基模型间具有强相关性，因此整体模型的方差近似等于基模型的方差。</p></blockquote><ul><li><p><code>Bagging</code> 主要关注降低方差，它能平滑强学习器的方差。因此它在非剪枝决策树、神经网络等容易受到样本扰动的学习器上效果更为明显。</p></li><li><p><code>Boosting</code> 主要关注降低偏差，它能将一些弱学习器提升为强学习器。因此它在 <code>SVM</code>、<code>KNN</code> 等不容易受到样本扰动的学习器上效果更为明显。</p></li></ul><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>随机森林算法背后的思想是群体智慧的体现，它通过随机的 <code>行采样</code> 和 <code>列采样</code> 构造不同的训练集，建立一个决策树森林，利用加权平均方式或多数表决的方式得到最后的预测结果，能够并行学习，对噪声和异常数据具有很好的过滤作用，因此有很广泛的应用。</p><p>随机森林的 <code>行采样</code> 和 <code>列采样</code> 都是为了减小模型之间的相关性使基学习器变得不同从而减小集成模型的方差。这种随机性会导致随机森林的偏差有所增加（相比于单棵决策树），因此随机森林的单棵树都会采用很深的决策树，并不进行剪枝操作，以减小每棵树的偏差，这使得每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从全部特征中选择部分来让每一棵决策树学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终再通过投票或平均得到结果。这也正是群体智慧的体现。</p><blockquote><p>随机森林是 <code>Bagging</code> 的一种扩展变体，与 <code>Bagging</code> &gt; 相比：</p><ul><li><p><code>Bagging</code> 中基学习器的 <code>多样性</code> 来自于样本扰动。&gt; 样本扰动来自于对初始训练集的随机采样。</p></li><li><p>随机森林中的基学习器的多样性不仅来自样本扰动，还来自属性扰动。</p><ul><li><p>传统决策树在选择划分属性时，是在当前结点的属性集合（假定有 $n$ 个属性）中选择一个最优属性。</p></li><li><p>随机森林中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含 $k$ 个属性的子集，然后再从这个子集中选择一个最优属性用于划分。（通常建议 $k=log_2n$）</p></li></ul></li></ul><p><strong>这使得最终集成的泛化性能可以通过个体学习器之间差异度的增加而进一步提升。</strong></p></blockquote><h1 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a><code>AdaBoost</code></h1><p><code>AdaBoost</code> 是基于 <code>Boosting</code> 的思想，通过多个弱分类器的线性组合来得到强分类器，训练时重点关注被错分的样本，准确率高的弱分类器权重大。</p><ul><li><p>在训练过程中，它不改变所给的训练数据，而是不断改变训练数据权值的分布，使得被误分类的数据再后一轮的分类中受到更大的关注。</p></li><li><p>同时采用加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在最后的表决中起更大的作用，减小分类误差率大的弱分类器的权值，使其在最后的表决中起较小的作用。所有弱分类器的权值之和并不为 $1$，是通过最后结果的符号来决定实例的类别，该结果的绝对值表示分类的确信度。</p></li></ul><blockquote><p><code>Adaboost</code> 还有另外一种理解，即可以认为其模型是加法模型、损失函数为指数函数、学习算法为前向分步算法的二类分类学习方法。</p><p>加法模型：多个基函数线性组合得到的模型</p><p>前向分步算法：对于加法模型，从前往后，每一步只学习一个基函数及其系数，而不是一次性学习所有的基函数，从而简化优化的复杂度。</p></blockquote><h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a><code>GBDT</code></h1><p><code>GBDT</code> 是基于 <code>Boosting</code> 的思想，串行地构造多棵决策树来进行数据的预测，它是<strong>在损失函数所在的函数空间中做梯度下降，即把待求的决策树模型当作参数，每轮迭代都去拟合损失函数在当前模型下的负梯度</strong>，从而使得参数朝着最小化损失函数的方向更新。</p><blockquote><p><code>GBDT</code> 可以看作是 <code>AdaBoost</code> 的一个推广，<code>AdaBoost</code> 是通过错分数据点来识别问题，通过调整错分数据点的权重来改进模型，<code>GBDT</code> 是通过负梯度来识别问题，通过计算负梯度来改进模型，实际上，负梯度绝对值大的样例同样会在之后的训练中受到更大的关注，因为它造成的损失更容易在最后的损失函数中占很大的比重，因此，需要更多地偏向于它去减小损失。这也是 <code>GBDT</code> 和 <code>AdaBoost</code> 相似的一个点，而相比 <code>AdaBoost</code>, <code>Gradient Boosting</code> 可以使用更多类型的损失函数，因此可以解决更多的问题。</p></blockquote><h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a><code>XGBoost</code></h1><p><code>XGBoost</code>是梯度提升树的一种高效系统实现，是对 <code>GBDT</code> 进一步的改进，包括对代价函数进行了二阶泰勒展开，在代价函数里加入了正则项，借鉴了随机森林的列采样方法，支持并行计算等。</p><ul><li><p>传统 <code>GBDT</code> 在优化时只用到一阶导数信息，<code>XGBoost</code> 则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。此外，<code>XGBoost</code> 工具支持自定义代价函数，只要函数可一阶和二阶求导。</p></li><li><p><code>XGBoost</code>在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点权重的 $L2$ 范数。从 <code>Bias-variance tradeoff</code> 角度来讲，正则项降低了模型的 <code>variance</code>，使学习出来的模型更加简单，防止过拟合，这也是 <code>XGBoost</code> 优于传统 <code>GBDT</code> 的一个特性。</p></li><li><p><code>Shrinkage</code>（缩减），相当于学习速率（<code>XGBoost</code> 中的<code>eta</code>）。<code>XGBoost</code> 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把 <code>eta</code> 设置得小一点，然后迭代次数设置得大一点。</p></li><li><p>列抽样，<code>XGBoost</code> 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。</p></li><li><p>对缺失值的处理。对于特征的值有缺失的样本，<code>XGBoost</code> 可以自动学习出它的分裂方向。</p></li><li><p>支持并行。<code>XGBoost</code> 的并行不是树粒度的并行，<code>XGBoost</code> 也是一次迭代完才能进行下一次迭代的。<code>XGBoost</code> 的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），<code>XGBoost</code> 在训练之前，预先对数据进行了排序，然后保存为 <code>Block</code> 结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个 <code>Block</code> 结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p></li><li><p>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以 <code>XGBoost</code> 还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p></li></ul><h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a><code>LightGBM</code></h1><p><code>LightGBM</code> 是一个实现 <code>GBDT</code> 算法的分布式高效框架。它通过 <code>leaf-wise</code> 分裂方法进行决策树的生成，通过基于直方图的算法寻找特征分割点，并支持并行学习，能够更高效的处理大数据。</p><p>要减少训练的复杂度，可以通过减少特征量和数据量来实现，即从行和列两个角度来减少数据，同时要尽可能少的影响最后的精度。在 <code>LightGBM</code> 中，就是这样做的，对应着 <code>GOSS</code> 和 <code>EFB</code>。</p><ul><li><p><code>Gradient-based One-Side Sampling (GOSS)</code>：<code>GBDT</code> 虽然没有数据权重，但每个数据实例有不同的梯度，根据计算信息增益的定义，梯度大的实例对信息增益有更大的影响，因此在下采样时，我们应该尽量保留梯度大的样本（预先设定阈值，或者最高百分位间），随机去掉梯度小的样本。此措施在相同的采样率下比随机采样获得更准确的结果，尤其是在信息增益范围较大时。</p></li><li><p><code>Exclusive Feature Bundling (EFB)</code>：通常在真实应用中，虽然特征量比较多，但是由于特征空间十分稀疏，许多特征几乎是互斥的，<code>EFB</code> 通过捆绑互斥的特征，并将捆绑问题归约到图着色问题，通过贪心算法求得近似解，以减少特征数量。</p></li><li><p>对于树的分裂方法，它通过 <code>leaf-wise</code> 分裂产生比 <code>level-wise</code> 分裂更复杂的树，能够实现更高的准确率。虽然这样有时候会导致过拟合，但可以通过设置 <code>max-depth</code> 参数来防止过拟合的发生。（每一次的生长都是选取分裂增益最高的节点，而不是对一层中的所有节点都进行分裂）。</p></li><li><p>其次，它使用基于直方图的算法，将连续的特征值分桶装进离散的箱子(<code>Bins</code>)，并通过直方图做差加速计算兄弟节点的直方图，能够加速训练过程，并实现更少的内存占用。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集成学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
